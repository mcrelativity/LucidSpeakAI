# ğŸ™ï¸ Intone (Ex LucidSpeakAI)

<div align="center">

![Intone Banner](https://img.shields.io/badge/Intone-AI%20Speech%20Analysis-0ea5e9?style=for-the-badge)

[![Live Demo](https://img.shields.io/badge/ğŸŒ_Live_Demo-intone.app-00C7B7?style=for-the-badge)](https://intone.app)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)
[![Next.js](https://img.shields.io/badge/Next.js_14-000000?style=for-the-badge&logo=next.js&logoColor=white)](https://nextjs.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)

**AI-Powered Speech Analysis Platform for Communication Excellence**

[ğŸ‡ºğŸ‡¸ English](#english) | [ğŸ‡ªğŸ‡¸ EspaÃ±ol](#espaÃ±ol)

</div>

---

<a name="english"></a>

## ğŸ‡ºğŸ‡¸ English

### ğŸ“– Overview

**Intone** is an advanced speech analysis platform that leverages artificial intelligence to help users improve their communication skills. By combining acoustic analysis, transcription, and AI-powered insights, Intone provides detailed feedback on speech patterns, clarity, pace, and more.

### âœ¨ Key Features

#### ğŸ¯ **Core Functionality**
- ğŸ¤ **Real-time Audio Recording** - Record directly in your browser
- ğŸ“ **AI Transcription** - Powered by Google Cloud Speech-to-Text
- ğŸ“Š **Acoustic Analysis** - Analyze pitch, volume, pace, and pauses
- ğŸ¤– **AI Insights** - Get personalized feedback using OpenAI GPT-4
- ğŸŒ **Bilingual Support** - Full Spanish and English interface

#### ğŸ’ **Advanced Features**
- ğŸ“ˆ **Speech Metrics Dashboard** - Visualize your progress over time
- ğŸ­ **Filler Word Detection** - Identify "um", "uh", and other fillers
- â±ï¸ **Pace Analysis** - Speaking rate and rhythm evaluation
- ğŸ”Š **Volume Consistency** - Track vocal projection
- ğŸ“‘ **Session History** - Review past recordings and improvements

#### ğŸ” **Security & Performance**
- ğŸ›¡ï¸ **Rate Limiting** - Protection against brute force attacks
- âœ… **Input Validation** - Sanitized inputs prevent XSS attacks
- ğŸ”’ **JWT Authentication** - Secure 7-day session tokens
- ğŸ“ **File Security** - Strict audio file validation (50MB max, 10min max)
- ğŸš€ **Fast Processing** - Optimized backend with Python 3.11

### ğŸ—ï¸ Tech Stack

#### **Frontend**
- **Framework**: Next.js 14 (React 18)
- **Styling**: Tailwind CSS
- **State Management**: React Context API
- **Audio**: Web Audio API, MediaRecorder
- **Charts**: Recharts
- **Payments**: PayPal SDK
- **i18n**: next-intl (ES/EN)

#### **Backend**
- **Framework**: FastAPI (Python 3.11)
- **Database**: Supabase (PostgreSQL)
- **AI/ML**:
  - Google Cloud Speech-to-Text
  - OpenAI GPT-4
- **Audio Processing**:
  - librosa (acoustic analysis)
  - pydub (audio manipulation)
  - scipy (signal processing)
- **Security**:
  - slowapi (rate limiting)
  - bcrypt (password hashing)
  - python-jose (JWT)

#### **Infrastructure**
- **Frontend Hosting**: Vercel
- **Backend Hosting**: Render
- **Database**: Supabase Cloud
- **Storage**: Google Cloud Storage
- **CDN**: Vercel Edge Network

### ğŸ“¦ Installation

#### Prerequisites
- Node.js 18+ and npm
- Python 3.11+
- Google Cloud account (for Speech API)
- Supabase account
- OpenAI API key (optional, for AI insights)

#### 1. Clone the Repository
```bash
git clone https://github.com/mcrelativity/LucidSpeakAI.git
cd LucidSpeakAI
```

#### 2. Frontend Setup
```bash
cd frontend
npm install

# Create .env.local
cp .env.example .env.local
# Edit .env.local with your credentials
```

**Frontend Environment Variables**:
```env
NEXT_PUBLIC_PAYPAL_CLIENT_ID=your_paypal_client_id
NEXT_PUBLIC_PAYPAL_PLAN_ID=your_plan_id
NEXT_PUBLIC_API_BASE=http://localhost:8001
```

#### 3. Backend Setup
```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Create .env
cp .env.example .env
# Edit .env with your credentials
```

**Backend Environment Variables**:
```env
SUPABASE_URL=your_supabase_url
SUPABASE_ANON_KEY=your_anon_key
SUPABASE_SERVICE_KEY=your_service_key
SECRET_KEY=your_jwt_secret
GOOGLE_APPLICATION_CREDENTIALS_JSON={"type":"service_account",...}
FRONTEND_URL=http://localhost:3000
```

#### 4. Database Setup

Run the SQL schema in your Supabase SQL editor:

```sql
-- Users table
CREATE TABLE users (
  id BIGSERIAL PRIMARY KEY,
  email TEXT UNIQUE NOT NULL,
  hashed_password TEXT NOT NULL,
  created_at BIGINT NOT NULL,
  minutes INTEGER DEFAULT 0,
  tier TEXT DEFAULT 'free',
  paypal_subscription_id TEXT,
  subscription_status TEXT,
  subscription_plan_id TEXT,
  subscription_start_time BIGINT,
  subscription_next_billing_time BIGINT
);

-- Sessions table
CREATE TABLE sessions (
  id BIGSERIAL PRIMARY KEY,
  user_email TEXT NOT NULL,
  session_id TEXT UNIQUE NOT NULL,
  created_at BIGINT NOT NULL,
  duration REAL,
  transcript TEXT,
  insights TEXT,
  acoustics JSONB,
  locale TEXT DEFAULT 'es'
);
```

#### 5. Run Development Servers

**Terminal 1 - Backend**:
```bash
cd backend
uvicorn main:app --reload --port 8001
```

**Terminal 2 - Frontend**:
```bash
cd frontend
npm run dev
```

Open http://localhost:3000 ğŸš€

### ğŸš€ Deployment

#### Deploy to Vercel (Frontend)
```bash
cd frontend
vercel
```

#### Deploy to Render (Backend)
1. Create new Web Service
2. Connect GitHub repository
3. Configure:
   - **Root Directory**: `backend`
   - **Build Command**: `bash render-build.sh`
   - **Start Command**: `uvicorn main:app --host 0.0.0.0 --port $PORT`
   - **Environment**: Add all backend env vars

### ğŸ“Š Project Structure

```
LucidSpeakAI/
â”œâ”€â”€ frontend/               # Next.js frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/           # App router pages
â”‚   â”‚   â”œâ”€â”€ components/    # React components
â”‚   â”‚   â”œâ”€â”€ context/       # Context providers
â”‚   â”‚   â”œâ”€â”€ services/      # API services
â”‚   â”‚   â””â”€â”€ translations/  # i18n files
â”‚   â”œâ”€â”€ public/            # Static assets
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ backend/               # FastAPI backend
â”‚   â”œâ”€â”€ main.py           # Main application
â”‚   â”œâ”€â”€ requirements.txt  # Python dependencies
â”‚   â””â”€â”€ render-build.sh   # Build script
â”‚
â”œâ”€â”€ docs/                 # Documentation
â””â”€â”€ README.md
```

### ğŸ”‘ API Endpoints

#### Authentication
- `POST /register` - User registration
- `POST /token` - Login (JWT)
- `GET /users/me` - Get current user

#### Audio Analysis
- `POST /upload-audio/` - Upload and analyze audio
- `GET /sessions` - Get user sessions
- `GET /sessions/{session_id}` - Get session details
- `DELETE /sessions/{session_id}` - Delete session

#### Payments
- `POST /paypal-webhook` - PayPal webhook handler

#### Health
- `GET /health` - Health check

### ğŸ“ˆ Roadmap

- [ ] Multi-language support (add more languages)
- [ ] Real-time speech analysis
- [ ] Team collaboration features
- [ ] Speech comparison with reference speakers
- [ ] Mobile apps (iOS/Android)
- [ ] Video recording support
- [ ] Custom AI models for specific industries

### ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### ğŸ‘¥ Authors

- **[@mcrelativity](https://github.com/mcrelativity)** - Creator & Maintainer

### ğŸ™ Acknowledgments

- Google Cloud Speech-to-Text for transcription
- OpenAI for AI insights
- Supabase for database infrastructure
- Vercel for frontend hosting
- Render for backend hosting

### ğŸ“§ Contact

- **Website**: [lucid-speak-ai.vercel.app](https://lucid-speak-ai.vercel.app)
- **Issues**: [GitHub Issues](https://github.com/mcrelativity/LucidSpeakAI/issues)

---

<a name="espaÃ±ol"></a>

## ğŸ‡ªğŸ‡¸ EspaÃ±ol

### ğŸ“– DescripciÃ³n

**LucidSpeak AI** es una plataforma avanzada de anÃ¡lisis del habla que aprovecha la inteligencia artificial para ayudar a los usuarios a mejorar sus habilidades de comunicaciÃ³n. Al combinar anÃ¡lisis acÃºstico, transcripciÃ³n e insights impulsados por IA, LucidSpeak proporciona retroalimentaciÃ³n detallada sobre patrones de habla, claridad, ritmo y mÃ¡s.

### âœ¨ CaracterÃ­sticas Principales

#### ğŸ¯ **Funcionalidad Principal**
- ğŸ¤ **GrabaciÃ³n de Audio en Tiempo Real** - Graba directamente en tu navegador
- ğŸ“ **TranscripciÃ³n con IA** - Impulsado por Google Cloud Speech-to-Text
- ğŸ“Š **AnÃ¡lisis AcÃºstico** - Analiza tono, volumen, ritmo y pausas
- ğŸ¤– **Insights de IA** - ObtÃ©n retroalimentaciÃ³n personalizada usando OpenAI GPT-4
- ğŸŒ **Soporte BilingÃ¼e** - Interfaz completa en espaÃ±ol e inglÃ©s

#### ğŸ’ **CaracterÃ­sticas Avanzadas**
- ğŸ“ˆ **Dashboard de MÃ©tricas** - Visualiza tu progreso a lo largo del tiempo
- ğŸ­ **DetecciÃ³n de Muletillas** - Identifica "eh", "um" y otros rellenos
- â±ï¸ **AnÃ¡lisis de Ritmo** - EvaluaciÃ³n de velocidad y cadencia al hablar
- ğŸ”Š **Consistencia de Volumen** - Seguimiento de proyecciÃ³n vocal
- ğŸ“‘ **Historial de Sesiones** - Revisa grabaciones pasadas y mejoras

#### ğŸ” **Seguridad y Rendimiento**
- ğŸ›¡ï¸ **Rate Limiting** - ProtecciÃ³n contra ataques de fuerza bruta
- âœ… **ValidaciÃ³n de Inputs** - Inputs sanitizados previenen ataques XSS
- ğŸ”’ **AutenticaciÃ³n JWT** - Tokens de sesiÃ³n seguros de 7 dÃ­as
- ğŸ“ **Seguridad de Archivos** - ValidaciÃ³n estricta de audio (mÃ¡x 50MB, 10min)
- ğŸš€ **Procesamiento RÃ¡pido** - Backend optimizado con Python 3.11

### ğŸ—ï¸ Stack TecnolÃ³gico

#### **Frontend**
- **Framework**: Next.js 14 (React 18)
- **Estilos**: Tailwind CSS
- **GestiÃ³n de Estado**: React Context API
- **Audio**: Web Audio API, MediaRecorder
- **GrÃ¡ficos**: Recharts
- **Pagos**: PayPal SDK
- **i18n**: next-intl (ES/EN)

#### **Backend**
- **Framework**: FastAPI (Python 3.11)
- **Base de Datos**: Supabase (PostgreSQL)
- **IA/ML**:
  - Google Cloud Speech-to-Text
  - OpenAI GPT-4
- **Procesamiento de Audio**:
  - librosa (anÃ¡lisis acÃºstico)
  - pydub (manipulaciÃ³n de audio)
  - scipy (procesamiento de seÃ±ales)
- **Seguridad**:
  - slowapi (rate limiting)
  - bcrypt (hashing de contraseÃ±as)
  - python-jose (JWT)

#### **Infraestructura**
- **Hosting Frontend**: Vercel
- **Hosting Backend**: Render
- **Base de Datos**: Supabase Cloud
- **Almacenamiento**: Google Cloud Storage
- **CDN**: Vercel Edge Network

### ğŸ“¦ InstalaciÃ³n

#### Requisitos Previos
- Node.js 18+ y npm
- Python 3.11+
- Cuenta de Google Cloud (para Speech API)
- Cuenta de Supabase
- API key de OpenAI (opcional, para insights de IA)

#### 1. Clonar el Repositorio
```bash
git clone https://github.com/mcrelativity/LucidSpeakAI.git
cd LucidSpeakAI
```

#### 2. ConfiguraciÃ³n del Frontend
```bash
cd frontend
npm install

# Crear .env.local
cp .env.example .env.local
# Editar .env.local con tus credenciales
```

**Variables de Entorno del Frontend**:
```env
NEXT_PUBLIC_PAYPAL_CLIENT_ID=tu_paypal_client_id
NEXT_PUBLIC_PAYPAL_PLAN_ID=tu_plan_id
NEXT_PUBLIC_API_BASE=http://localhost:8001
```

#### 3. ConfiguraciÃ³n del Backend
```bash
cd backend
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
pip install -r requirements.txt

# Crear .env
cp .env.example .env
# Editar .env con tus credenciales
```

**Variables de Entorno del Backend**:
```env
SUPABASE_URL=tu_supabase_url
SUPABASE_ANON_KEY=tu_anon_key
SUPABASE_SERVICE_KEY=tu_service_key
SECRET_KEY=tu_jwt_secret
GOOGLE_APPLICATION_CREDENTIALS_JSON={"type":"service_account",...}
FRONTEND_URL=http://localhost:3000
```

#### 4. ConfiguraciÃ³n de Base de Datos

Ejecuta el esquema SQL en tu editor SQL de Supabase:

```sql
-- Tabla de usuarios
CREATE TABLE users (
  id BIGSERIAL PRIMARY KEY,
  email TEXT UNIQUE NOT NULL,
  hashed_password TEXT NOT NULL,
  created_at BIGINT NOT NULL,
  minutes INTEGER DEFAULT 0,
  tier TEXT DEFAULT 'free',
  paypal_subscription_id TEXT,
  subscription_status TEXT,
  subscription_plan_id TEXT,
  subscription_start_time BIGINT,
  subscription_next_billing_time BIGINT
);

-- Tabla de sesiones
CREATE TABLE sessions (
  id BIGSERIAL PRIMARY KEY,
  user_email TEXT NOT NULL,
  session_id TEXT UNIQUE NOT NULL,
  created_at BIGINT NOT NULL,
  duration REAL,
  transcript TEXT,
  insights TEXT,
  acoustics JSONB,
  locale TEXT DEFAULT 'es'
);
```

#### 5. Ejecutar Servidores de Desarrollo

**Terminal 1 - Backend**:
```bash
cd backend
uvicorn main:app --reload --port 8001
```

**Terminal 2 - Frontend**:
```bash
cd frontend
npm run dev
```

Abre http://localhost:3000 ğŸš€

### ğŸš€ Despliegue

#### Desplegar en Vercel (Frontend)
```bash
cd frontend
vercel
```

#### Desplegar en Render (Backend)
1. Crear nuevo Web Service
2. Conectar repositorio de GitHub
3. Configurar:
   - **Root Directory**: `backend`
   - **Build Command**: `bash render-build.sh`
   - **Start Command**: `uvicorn main:app --host 0.0.0.0 --port $PORT`
   - **Environment**: Agregar todas las variables de entorno del backend

### ğŸ“Š Estructura del Proyecto

```
LucidSpeakAI/
â”œâ”€â”€ frontend/               # Frontend Next.js
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/           # PÃ¡ginas del app router
â”‚   â”‚   â”œâ”€â”€ components/    # Componentes React
â”‚   â”‚   â”œâ”€â”€ context/       # Proveedores de contexto
â”‚   â”‚   â”œâ”€â”€ services/      # Servicios de API
â”‚   â”‚   â””â”€â”€ translations/  # Archivos i18n
â”‚   â”œâ”€â”€ public/            # Assets estÃ¡ticos
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ backend/               # Backend FastAPI
â”‚   â”œâ”€â”€ main.py           # AplicaciÃ³n principal
â”‚   â”œâ”€â”€ requirements.txt  # Dependencias Python
â”‚   â””â”€â”€ render-build.sh   # Script de build
â”‚
â”œâ”€â”€ docs/                 # DocumentaciÃ³n
â””â”€â”€ README.md
```

### ğŸ”‘ Endpoints de la API

#### AutenticaciÃ³n
- `POST /register` - Registro de usuario
- `POST /token` - Login (JWT)
- `GET /users/me` - Obtener usuario actual

#### AnÃ¡lisis de Audio
- `POST /upload-audio/` - Subir y analizar audio
- `GET /sessions` - Obtener sesiones del usuario
- `GET /sessions/{session_id}` - Obtener detalles de sesiÃ³n
- `DELETE /sessions/{session_id}` - Eliminar sesiÃ³n

#### Pagos
- `POST /paypal-webhook` - Manejador de webhook de PayPal

#### Salud
- `GET /health` - VerificaciÃ³n de salud

### ğŸ“ˆ Hoja de Ruta

- [ ] Soporte multi-idioma (agregar mÃ¡s idiomas)
- [ ] AnÃ¡lisis de habla en tiempo real
- [ ] Funciones de colaboraciÃ³n en equipo
- [ ] ComparaciÃ³n de habla con oradores de referencia
- [ ] Apps mÃ³viles (iOS/Android)
- [ ] Soporte de grabaciÃ³n de video
- [ ] Modelos de IA personalizados para industrias especÃ­ficas

### ğŸ¤ Contribuir

Â¡Las contribuciones son bienvenidas! Por favor sigue estos pasos:

1. Haz fork del repositorio
2. Crea una rama de feature (`git checkout -b feature/CaracteristicaIncreible`)
3. Commit tus cambios (`git commit -m 'Agregar alguna CaracteristicaIncreible'`)
4. Push a la rama (`git push origin feature/CaracteristicaIncreible`)
5. Abre un Pull Request

### ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

### ğŸ‘¥ Autores

- **[@mcrelativity](https://github.com/mcrelativity)** - Creador y Mantenedor

### ğŸ™ Agradecimientos

- Google Cloud Speech-to-Text por la transcripciÃ³n
- OpenAI por los insights de IA
- Supabase por la infraestructura de base de datos
- Vercel por el hosting del frontend
- Render por el hosting del backend

### ğŸ“§ Contacto

- **Sitio Web**: [lucid-speak-ai.vercel.app](https://lucid-speak-ai.vercel.app)
- **Issues**: [GitHub Issues](https://github.com/mcrelativity/LucidSpeakAI/issues)

---

<div align="center">



â­ Star this repo if you find it useful!

</div>
